# Prediction Project
Group 5
by: Derek Fine, Dexter Offer, Matt Webber, Mitchell Stephens, and Nora Cheikh

## Section 1: Executive Summary and Documentation of Preprocessing

{Executive Summary}
### Cleaning Process
#### Pull in Raw Datasets
Data was downloaded onto desktop from: https://github.com/slevkoff/ECON386REPO/tree/master/Prediction%20Project
First, the csv files were loaded into R.
The raw training dataset has 160 variables and 19,622 observations.
The raw testing dataset has 160 variables and 20 observations.
```{r} 
setwd("~/Desktop") #set the working directory
filename <- "testing.csv" #create label for filename
Testing <- read.csv(filename) #pull csv data frame into RStudio
filename <- "training.csv" #create label for filename
Training <- read.csv(filename) #pull csv data frame into RStudio
```
#### Removal of NAs and empty variables
Some of the variables were removed because all or most of the values were NA or empty vectors. 
```{r}
testing1 <- Filter(function(x)!all(is.na(x) || is.null(x) || x == "" || x == 0), Testing) #remove columns that are empty or have NAs
testing1$problem_id <-NULL #remove the "problem_id" column from testing data
training1 <- Training[ , colSums(is.na(Training)) == 0]
testing1names <- colnames(testing1)
write.table(testing1names, file="testingnames.txt")
training1names <- colnames(training1)
write.table(training1names, file="training1names.txt")
#compare the column names
training2 <- training1[ -c(12:20,43:48,52:60,74:82) ] #manually remove the columns that are in training1 but not in testing1 and label new data frame training2
```
#### Save the Clean Datasets
The new datasets should preserve the original number of observations and change the number of variables in the training set to 60 and in the testing set to 59.
```{r}
write.csv(training2, file="cleantraining.csv", row.names = FALSE)
write.csv(testing1, file="cleantesting.csv", row.names = FALSE)
```

## Section 2: Model Proposed by

## Section 3: Model Proposed by

## Section 4: Model Proposed by

## Section 5: Model Proposed by 

## Section 6: Model Proposed by Nora Cheikh
### Load The Clean Datasets
```{r}
cleantraining <- read.csv("cleantraining.csv") #load the clean training set
cleantesting <- read.csv("cleantesting.csv") #load the clean testing set
```
### Fix the Levels of the Testing Set
The levels of the testing set do not match the levels of the training set because the testing set only has 20 observations, so the levels do not vary as much.
```{r}
levels.time <- levels(cleantraining$cvtd_timestamp) #create vector of the levels of the cvtd_timestamp
levels(cleantesting$cvtd_timestamp) <- levels.time #change the levels of cvtd_timestamp in the testing set to match the training set
levels.window <- levels(cleantraining$new_window) #do the same for the new_window variable
levels(cleantesting$new_window) <- levels.window
```
### Partition the In-Sample Testing and Training Sets
Partition the *cleantraining* data into two sections: 70% for training the model and 30% to test how well the model predicts and to not overfit the data.
```{r}
 set.seed(1234) #random number generator; randomize selecetion of the sample subsets
 trainingRowIndex<-sample(1:nrow(cleantraining), size = .7*nrow(cleantraining)) 
 #partition 70% of the data for the training, 30% of the data for testing
 trainingData1<-cleantraining[trainingRowIndex, ] #create training set
 testData1 <-cleantraining[-trainingRowIndex, ] #create testing set
```
### Support Vector Machine Model
A support vector machine is a supervised learning model that can be used for classification. After researching other studies that predicted movement data, I found the support vector machine to be a popular choice of model. I used all of the variables, except for the *X* and the *new_window* variables. To find the optimal parameters, I tuned the model using command {best.svm()} that did a grid search which creates a set of models and cross-validates to find the best model. The model has 2976 support vectors.
```{r}
install.packages(e1071) #for the support vector machine (svm) commands 
library(e1071)
install.packages(caret) #for the confusion matrix
library(caret)
model.nc <- best.svm(classe~.-X -new_window, data = trainingData1, cost = 2^(2:8),  kernel = "radial")
#use best.svm command to find the best predictive model; using a grid search over the parameter ranges
#estimate classe based on all the variables (.), minus...
#X: this is a id variable, since the observations are in order by class, it would memorize with this variable
#new_window: this is a dummy variable; in the test dataframe, all the observations are "no", so it is not informative
#cost is a tuning parameter for C-classification; weight for the soft margin
#radial kernal:radial basis function (RBF)/Gaussian kernel; used to get the best predictive performance
```

### Test/Cross-Validate Model
The evaluation of how well this model is at predicting the classe classifications. From the confusion matrix, the model is found to be predict the testing set with 99.49% accuracy; the 95% confidence interval is between .9927 and .9966; the p-value is less than 2.2e-16.
```{r}
predict1 <- predict(model.nc, testData1) #creates prediction of classe with the in-sample testing data
confusionMatrix(predict1,testData1$classe)
#table to describe the perfomance of the classification model
```
### Predict The Out-of-Sample Classifications
The prediction of the the out-of-sample dataset class.
```{r}
predict <- predict(model.nc, cleantesting)
```
### Proposed Prediction by Model
Problem_id | 1|2|3|4|5|6|7|8|9|10|11|12|13|14|15|16|17|18|19|20
------- | -|-|-|-|-|-|-|-|-|--|--|--|--|--|--|--|--|--|--|--
__classe__|


## Section 7: Final Proposal and Discussion 
