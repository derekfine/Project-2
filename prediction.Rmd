# Prediction Project
> Group 5
> by: Derek Fine, Dexter Offer, Matt Webber, Mitchell Stephens, and Nora Cheikh

## Section 1: Executive Summary and Documentation of Preprocessing
{Executive Summary}
### Cleaning Process
#### Pull in Raw Datasets
> Data was downloaded onto desktop from: https://github.com/slevkoff/ECON386REPO/tree/master/Prediction%20Project
> First, the csv files were loaded into R.
> The raw training dataset has 160 variables and 19,622 observations.
> The raw testing dataset has 160 variables and 20 observations.
```{r} 
setwd("~/Desktop") #set the working directory
filename <- "testing.csv" #create label for filename
Testing <- read.csv(filename) #pull csv data frame into RStudio
filename <- "training.csv" #create label for filename
Training <- read.csv(filename) #pull csv data frame into RStudio
```
#### Removal of NAs, Empty, and Unnecessary Columns
> Some of the variables were removed because all or most of the values were NA or empty vectors. 
```{r}
testing1 <- Filter(function(x)!all(is.na(x) || is.null(x) || x == "" || x == 0), Testing) #remove columns that are empty or have NAs
testing1$problem_id <-NULL #remove the "problem_id" column from testing data
training1 <- Training[ , colSums(is.na(Training)) == 0]
testing1names <- colnames(testing1)
write.table(testing1names, file="testingnames.txt")
training1names <- colnames(training1)
write.table(training1names, file="training1names.txt")
#compare the column names
training2 <- training1[ -c(12:20,43:48,52:60,74:82) ] #manually remove the columns that are in training1 but not in testing1 and label new data frame training2
```
#### Save the Clean Datasets
> The new datasets should preserve the original number of observations and change the number of variables in the training set to 60 and in the testing set to 59.
```{r}
write.csv(training2, file="cleantraining.csv", row.names = FALSE)
write.csv(testing1, file="cleantesting.csv", row.names = FALSE)
```
{Data Analysis?}
## Section 2: Model Proposed by

## Section 3: Model Proposed by

## Section 4: Model Proposed by

## Section 5: Model Proposed by 

## Section 6: Model Proposed by Nora Cheikh
### Load The Clean Datasets
```{r}
cleantraining <- read.csv("cleantraining.csv") #load the clean training set
cleantesting <- read.csv("cleantesting.csv") #load the clean testing set
```
### Fix the Levels of the Testing Set
> The levels of the testing set do not match the levels of the training set because the testing set only has 20 observations, so the levels do not vary as much.
```{r}
levels.time <- levels(cleantraining$cvtd_timestamp) #create vector of the levels of the cvtd_timestamp
levels(cleantesting$cvtd_timestamp) <- levels.time #change the levels of cvtd_timestamp in the testing set to match the training set
levels.window <- levels(cleantraining$new_window) #do the same for the new_window variable
levels(cleantesting$new_window) <- levels.window
```
### Partition the In-Sample Testing and Training Sets
> Partition the *cleantraining* data into two sections: 70% for training the model and 30% to test how well the model predicts and to not overfit the data.
```{r}
 set.seed(1234) #random number generator; randomize selection of the sample subsets
 trainingRowIndex<-sample(1:nrow(cleantraining), size = .7*nrow(cleantraining)) 
 #partition 70% of the data for the training, 30% of the data for testing
 trainingData1<-cleantraining[trainingRowIndex, ] #create training set
 testData1 <-cleantraining[-trainingRowIndex, ] #create testing set
```
### Support Vector Machine Model
> A support vector machine is a supervised learning model that can be used for classification. After researching other studies that predicted movement data, I found the support vector machine to be a popular choice of model for this particular type of data classification. I used the *e1071* R package to estimate the model.
> I used all of the variables, except for the *X* and the *new_window* variables. *X* is an id variable and *new_window* indicates a change in window, which all values were 'no' in the testing data, so it is not informative. 
> To find the optimal parameters, I tuned the model using command {best.svm()} that did a grid search which creates a set of models and cross-validates to find the best model. The cost is a tuning parameter for C-classification; it weights for the soft margin. I used a radial basis (RBF) function to get the best predictive performance based on the high number of variables in this dataset.
> The model has 2976 support vectors.
```{r}
install.packages(e1071) #for the support vector machine (svm) commands 
library(e1071)
model.nc <- best.svm(classe~.-X -new_window, data = trainingData1, cost = 2^(2:8),  kernel = "radial")
```

### Test/Cross-Validate Model
> The evaluation of how well this model is at predicting the classe classifications. I used the *caret* R package to cross-validate the model. Using the predict() command, I used the model to predict the in-sample testing data.
> To test how well the model predicted the in-sample testing data, I used a confusion matrix. A confusion matrix is a table that describes the performance of the classification test. Results are shown below.
```{r}
install.packages(caret) #for the confusion matrix
library(caret)
predict1 <- predict(model.nc, testData1) #creates prediction of classe with the in-sample testing data
confusionMatrix(predict1,testData1$classe)
#table to describe the perfomance of the classification model
```
Results of the Confusion Matrix
 | 
----------|--------
Accuracy | 99.49%
95% Confidence Interval | ( .9927, .9966)
P-value | <2.2e-16
### Predict The Out-of-Sample Classifications
> The prediction of the the out-of-sample dataset class.
```{r}
predict <- predict(model.nc, cleantesting)
```
### Predictions for Out-of-Sample Classification
Problem_id | 1|2|3|4|5|6|7|8|9|10|11|12|13|14|15|16|17|18|19|20
------- | -|-|-|-|-|-|-|-|-|--|--|--|--|--|--|--|--|--|--|--
__classe__|B|A|B|A|A|E|D|B|A|A|B|C|B|A|E|E|A|B|B|B


## Section 7: Final Proposal and Discussion 
### Predictions by Model
Problem_id | 1|2|3|4|5|6|7|8|9|10|11|12|13|14|15|16|17|18|19|20
------- | -|-|-|-|-|-|-|-|-|--|--|--|--|--|--|--|--|--|--|--
__classe__|B|A|B|A|A|E|D|B|A|A|B|C|B|A|E|E|A|B|B|B
